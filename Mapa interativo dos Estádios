from bs4 import BeautifulSoup
import requests
import pandas as pd
import geopandas as gpd
import folium


# In[2]:


#link da wikipedia com os dados utilizados
wiki_estadios = "https://pt.wikipedia.org/wiki/Lista_dos_maiores_est%C3%A1dios_de_futebol_do_Brasil"


# In[3]:


#Utilizei o requests para obter o HTML da página
response = requests.get(wiki_estadios)


# In[4]:


#Utilizei a biblioteca BeautifulSoup para analisar o html
soup = BeautifulSoup(response.text , "html.parser")


# In[5]:


#Após inspecionar o código da pagína identifiquei que o contéudo da tabela pode ser encontrado buscando o "table"
pegar_tabela = soup.find("table" )


# In[6]:


#Agora utilizei o pandas para ler o conteúdo da variável "pegar tabela"
df = pd.read_html(str(pegar_tabela))


# In[7]:


#Como podemos observar o conteúdo veio em forma de lista
df


# In[8]:


#Aqui transformei a lista em Dataframe
Df_Estadios = df[0]


# In[9]:


#Esse comando faz com que plotemos o dataframe inteiro e não extritamente necessário.
pd .set_option("display.max_rows", None, "display.max_columns", None)







# In[10]:


Df_Estadios


# In[11]:


#Verificamos os tipos de dados
Df_Estadios.dtypes


# In[12]:


#Os procedimentos seguintes foram para o ponto da coluna capacidade e interpre-la como INT sem distorção
Df_Estadios['Capacidade'] = Df_Estadios['Capacidade']*1000 
Df_Estadios.dropna(inplace= True)


# In[13]:


Df_Estadios["Capacidade"] = Df_Estadios["Capacidade"].astype(int)
Df_Estadios








# In[14]:


#Aqui temos o dataframe com a coluna capacidade tratada
Df_Estadios


# In[15]:


#Agora selecionamos apenas os estadios da região sul
r_sul = Df_Estadios.loc[(Df_Estadios["Unidade federativa"] == "RS")| (Df_Estadios["Unidade federativa"] == "SC")| (Df_Estadios["Unidade federativa"] == "PR")]


# In[16]:


r_sul


# In[17]:


del r_sul["Pos."]


# In[18]:


r_sul.reset_index(drop=True, inplace=True)
r_sul







# Agora vamos trabalhar com as bibliotecas de dados espaciais para fazer a geolocalização, tratamento e criar os mapas.
# 

# In[19]:


#Aqui criei um looping para Geocodificar e pegar as coordenadas dos estádios
from geopy.geocoders import Nominatim
e_latitude = []
e_longitude =  []
e_location = []
estadios_nao_encontrados = []
#Aqui usei o try para tentar localizar as coordenadas, caso não encontre o except preenche as listas com os estadios nao encontrados
for estadio in r_sul["Estádio"]:
    try:
        geolocator = Nominatim(user_agent="u_pods_bf")
        location = geolocator.geocode("Estádio " + estadio)
        e_latitude.append(location.latitude)
        e_longitude.append(location.longitude)
        e_location.append(location)
    except AttributeError:
        estadios_nao_encontrados.append(estadio)
        e_latitude.append(0)
        e_longitude.append(0)
        e_location.append("NaN")
        print(estadio)
  
            
        

                


# In[20]:


#Fiz uma busca para encontrar os NAN
e_longitude





# In[21]:


#Aqui inseri o conteúdo das listas no dataframe
r_sul["Latitude"] = e_latitude
r_sul["Longitude"] = e_longitude
r_sul["End"] = e_location







# In[22]:


#Aqui inseri o conteúdo das listas no dataframe
r_sul["Latitude"] = e_latitude
r_sul["Longitude"] = e_longitude
r_sul["Endereco"] = e_location


# In[23]:


#Transformei em Geodataframe
Gdf_Estadios = gpd.GeoDataFrame(
    r_sul, geometry=gpd.points_from_xy(r_sul.Longitude, r_sul.Latitude))


# In[ ]:





# In[24]:


Gdf_Estadios







# In[25]:


#Verifiquei o conteúdo(podemos perceber alguns erros)
Gdf_Estadios.plot()


# In[26]:


#Aqui verifiquei apenas os estadios que possuem coordenadas para observarmos melhor.
checagem = Gdf_Estadios.loc[Gdf_Estadios["Latitude"] != 0]


# In[27]:


#A Longitude mais baixa no Brasil é de -53o 23'50", no gráfico é possível observar que tem um ponto abaixo disso.
checagem.plot()


# In[28]:


#Puxei o shapefile dos municipios brasileiros para auxiliar nas correções
cidades = gpd.read_file("C:/Users/eduar/OneDrive/Área de Trabalho/Curso GeoPandas/br_municipios_20200807/BR_Municipios_2019.shp", index_col = "NM_MUN")


# In[29]:


cidades.plot()


# In[30]:


#Vamos verificar o conteúdo do shape para ver como podemos usa-lo
cidades.tail()


# Podemos observar que temos uma coluna com o nome dos municípios em UTF-8. Vamos tentar usa-la para fazer a correção.
# 

# In[31]:


#Repare que os municípios dos estádios podem ser encontrados na coluna localidade.
Gdf_Estadios


# In[32]:


#Então vamos usar o comando "isin" para verificar se podemos encontrar todos os municpios da tabela dos estadios no shape dos municpios.
Gdf_Estadios.Localidade.isin(cidades.NM_MUN).astype(bool)


# In[33]:


#Antes de seguirmos,é muito importante verificar se os geodataframes estão no mesmo sistema de coordenadas.
print(cidades.crs)
print(Gdf_Estadios.crs)


# In[34]:


#Vamos ajustar o sistema de coordenadas dos estádios
Gdf_Estadios.set_crs("EPSG:4326", inplace= True)


# Agora vamos selecionar apenas as cidades com os estádios.

# In[35]:


#Vamos armazenar o resultado na variável abaixo.
cidades_com_estadio = cidades.loc[cidades.NM_MUN.isin(Gdf_Estadios.Localidade) == True]
cidades_com_estadio.plot()


# In[36]:


#Agora temos uma série de polígonos com as cidades de interesse.
cidades_com_estadio


# In[37]:


#Para facilitar os procedimentos seguintes vamos transformar a lista de poligonos em apenas um multipolygon.
shape_unico = cidades_com_estadio.geometry.unary_union
shape_unico


# In[ ]:





# In[38]:


#Agora armazenamos a geometria em um geodataframe
envgdf = gpd.GeoDataFrame(gpd.GeoSeries(shape_unico),index = None )
envgdf


# In[39]:


envgdf = envgdf.rename(columns={0:'geometry'}).set_geometry('geometry')


# In[40]:


envgdf.set_crs("EPSG:4326",inplace = True)
    


# In[41]:


envgdf.plot()


# In[42]:


#Fazemos uma avaliação dos dois geodataframes sobrepostos.
ax = envgdf.plot(figsize=(20,20), color='red', edgecolor='gainsboro', zorder=3)
Gdf_Estadios.plot(ax=ax, markersize=25)


# In[43]:


print(envgdf.crs)
print(Gdf_Estadios.crs)


# Agora utilizaremos duas técnicas de "overlay" muito utilizadas em Geoprocessamento e análise espacial, o intersection e o a Symmetrical Difference
# Você pode saber mais nesse link: https://geopandas.org/set_operations.html
# 
# 
# 

# In[ ]:





# In[86]:


O intersection sobrepoe as duas camadas(estadios e poligo da cidades) e retorna apenas aqueles que sobrepõem.
intersecao = gpd.overlay(Gdf_Estadios,envgdf, how = "intersection")
intersecao


# In[45]:


# O symmetric difference faz exatamente o oposto, retorna os objetos que não se sobrepoem.
diferenca = gpd.overlay(Gdf_Estadios,envgdf, how = "symmetric_difference")
diferenca


# Agora vamos nos atentar primeiramente ao geodataframe da diferença. Pois ele indica todos os estádios que não estão localizados no municípios indicados pela coluna localidade(obviamente os que preenchemos com coordenadas "0.0000" estão nessa lista)

# In[ ]:





# # Voltando para o Scrapping

# Aqui vamos retornar para as técnicas de webscrapping para tentar encontrar os endereços corretos dos estádios. 
# 
# Vamos o utilizar a própria busca do google para pegar o endereço corretor buscando pelo estádio e pelo municipio da coluna localidade procurando eliminar os erros de encontrados na coluna diferenca.

# In[46]:


auxiliar = []
for index,row in diferenca.iterrows():
    try:
        busca_google = requests.get("https://www.google.com/search?q="+"Estádio "+row["Estádio"]+" "+row["Localidade"])
        soup = BeautifulSoup(busca_google.text,"html.parser")
        resultado2 = soup.find_all("span",class_="BNeawe tAd8D AP7Wnd")
        auxiliar.append(resultado2[0].text)
    except IndexError:
        auxiliar.append("Não encontrado")
        
    
    


# In[47]:


auxiliar


# In[48]:


ajustado = []
for item in auxiliar:
    ajuste = item.replace("-", ",",1)
    ajustado.append(ajuste)


# In[49]:


ajustado




# Após alguns testes, verifiquei que o OpenStreetMap encontra os endereços de rua quando utilizamos o identificador "Rua" ao invés de "R.".
# 
# Então vamos criar um loop para que quando ele se depare com esse erro de geocodificação, não substituimos r. por Rua.
# 
# Depois vamos colocar cada fragmento do endereço separado por "," em listas diferentes que utilizaremos para criar diversas combinações até que o OpenStreetMap localize todos os estádios.

# In[50]:


l0 = []
l1 = []
l2 = []
l3 = []
l4 = []
for item in ajustado:  
    try:
        l0.append(item.split(",")[0])
        l1.append(item.split(",")[1])
        l2.append(item.split(",")[2])
        l3.append(item.split(",")[3])
        l4.append(item.split(",")[4])
    except IndexError:
        l4.append("")

        
diferenca["l0"] = l0
diferenca["l1"] = l1
diferenca["l2"] = l2
diferenca["l3"] = l3
diferenca["l4"] = l4       


# In[51]:


diferenca


# In[52]:


for item in diferenca["l0"]:
    if item.startswith("0") or item.startswith("1") or item.startswith("2") or item.startswith("3") or item.startswith("4") or item.startswith("5") or item.startswith("6") or item.startswith("7") or item.startswith("8") or item.startswith("9"):
        print(item)
        diferenca["l0"].replace(item, "auxiliar",inplace = True)


# In[53]:


diferenca


# In[54]:


for index,row in diferenca.iterrows():
    if row["l0"] == "auxiliar":
        diferenca.replace({row["l0"] : row["l1"],
        row["l1"] : row["l2"],
        row["l2"] : row["l3"],row["l3"] : row["l4"]},inplace = True)
    elif row["l4"] == "":
        diferenca.replace({row["l0"] : "",
        row["l1"] : row["l0"],
        row["l2"] : row["l1"],row["l3"] : row["l2"],row["l4"] : row["l3"]},inplace = True)
    
        


# In[55]:


diferenca


# In[56]:


diferenca["l3"][6] = diferenca["l2"][6] + "-" + diferenca["l3"][6]
diferenca["l2"][6] = diferenca["l1"][6]
diferenca["l1"][6] = ""


# In[57]:


diferenca






# In[58]:


diferenca["l0"].replace(regex=[r'^ba.$', 'R. '], value='Rua ', inplace = True)
diferenca


# In[90]:


del diferenca["End"]
del diferenca["Endereco"]


# In[92]:


diferenca.rename(columns={"l0": "Log", "l1": "Num","l2": "Bairro", "l3": "Cidade", "l4": "Cep"}, inplace = True)


# In[93]:


diferenca


# Agora vamos fazer um loop que testará diversas combinações entre as colunas com os fragmentos dos endereços até que todos sejam encontrados.
# 
# Foi criado uma hierarquia na busca, a coluna onde se concentram os nomes de rua aparecem em todas as tentativas por ser uma informação essencial. 
# 
# Em datases maiores possivelmente serão necessárias mais combinações, mas é essencial não omitir as colunas mais importantes.

# In[61]:


e_latit = []
e_longit = []
e_locat = []
for index, row  in diferenca.iterrows():
    try:
        geolocator = Nominatim(user_agent="Eduardo")
        localizacao = geolocator.geocode(row["Log"] + "," + row["Num"] + "," + row["Bairro"]+ "," + row["Cidade"] + "," + row["Cep"])
        e_latit.append(localizacao.latitude)
        e_longit.append(localizacao.longitude)
        e_locat.append(localizacao)
    except AttributeError:
        try:
            geolocator = Nominatim(user_agent="Eduardo")
            localizacao = geolocator.geocode(row["Log"] + "," + row["Num"] + "," + row["Bairro"]+ "," + row["Cidade"])
            e_latit.append(localizacao.latitude)
            e_longit.append(localizacao.longitude)
            e_locat.append(localizacao)
        except AttributeError:
            try:
                localizacao3 = geolocator.geocode(row["Log"] + ","  + row["Bairro"]+ "," + row["Cidade"])
                e_latit.append(localizacao3.latitude)
                e_longit.append(localizacao3.longitude)
                e_locat.append(localizacao3)
            except AttributeError:
                try:
                    localizacao4 = geolocator.geocode(row["Log"] + ","  + row["Num"]+ "," + row["Cidade"])
                    e_latit.append(localizacao4.latitude)
                    e_longit.append(localizacao4.longitude)
                    e_locat.append(localizacao4)
                except AttributeError:
                    try:
                        localizacao5 = geolocator.geocode(row["Bairro"]+ "," + row["Cidade"] + "," + row["l4"])
                        e_latit.append(localizacao5.latitude)
                        e_longit.append(localizacao5.longitude)
                        e_locat.append(localizacao5)
                    except AttributeError:
                        try:
                            localizacao6 = geolocator.geocode(row["Log"]+ "," + row["Cidade"] + "," + row["l4"])
                            e_latit.append(localizacao6.latitude)
                            e_longit.append(localizacao6.longitude)
                            e_locat.append(localizacao6)
                        except AttributeError:
                            e_latit.append("0")
                            e_longit.append("0")
                            e_locat.append("NaN")
                    
                      
                
            
            
            
    

    

    


# In[62]:


e_locat







# In[63]:


#Aqui substituiremos as coordenadas antingas pelas ajustadas no loop.
diferenca["Latitude"] = e_latit
diferenca["Longitude"] = e_longit


# In[ ]:





# In[64]:


diferenca


# In[65]:



diferenca = gpd.GeoDataFrame(
    diferenca, geometry=gpd.points_from_xy(diferenca.Longitude, diferenca.Latitude))
    
  
     
        
        
        
        
        


# In[ ]:





# Agora vamos juntar o geodataframe diferenca com o intersecao que criamos lá atrás.
# 

# In[101]:


coord_corrigidas = intersecao.append(diferenca)


# In[67]:


corrigido


# In[68]:


coord_corrigidas.plot()


# In[ ]:





# In[77]:


corrigido["Capacidade"] = corrigido["Capacidade"].astype('int64')


# In[79]:


corrigido["Capacidade"]


# In[94]:


corrigido["Capacidade"] = corrigido["Capacidade"].astype('str')


# In[ ]:





# In[ ]:





# Agora importamos o folium e criamos o mapa interativo

# In[70]:


import folium 


# In[71]:


# Criamos o o mapa
estadios_do_rsul = folium.Map( zoom_starts = 2)


# In[98]:


#Fazemos um loop para anexarmos os estádios no mapa
for index, row in corrigido.iterrows():
    
    folium.Marker([row['Latitude'], row['Longitude']],popup = row['Estádio'] + '<br>' '<br>'  'Capacidade: ' + row['Capacidade']).add_to(estadios_do_rsul)


# In[99]:


#estadios_do_rsul


# In[100]:


#Salvando o arquivo HTML
estadios_do_rsul.save("rsul.html")
